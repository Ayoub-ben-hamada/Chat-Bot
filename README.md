# ğŸ¤– AI Chatbot with Flask, React & Ollama

This project is a simple but powerful AI chatbot built with:
- **Frontend**: React (deployed with Vercel)
- **Backend**: Flask (deployed with Render)
- **AI Engine**: Ollama (runs locally)

---

## âœ¨ Features

- Clean and responsive user interface
- Chat with LLMs like LLaMA 3 or Phi-3
- Easy to customize and extend
- Communicates with a Flask backend which talks to Ollama

---

## âš™ï¸ How It Works

1. The **React frontend** sends a message to the Flask API.
2. The **Flask backend** forwards that message to Ollama's local API.
3. Ollama responds with a reply generated by your chosen model (e.g., llama3 or phi3).
4. The reply is displayed in the React interface.

---

## ğŸš€ Live Demo

- ğŸ”— Frontend: (https://chatbot-react25.netlify.app/)
- ğŸ”— Backend: [https://mychatbot-backend.onrender.com](https://mychatbot-backend.onrender.com)

---

## ğŸ› ï¸ Local Installation

### 1. Prerequisites

- [Node.js](https://nodejs.org/)
- [Python 3.10+](https://www.python.org/)
- [Ollama](https://ollama.com/) â€” **must be installed and running locally**

### 2. Backend Setup

```bash
git clone https://github.com/your-username/your-backend-repo.git
cd backend-folder
pip install -r requirements.txt
ollama run llama3  # or `phi3` for lightweight
python app.py
